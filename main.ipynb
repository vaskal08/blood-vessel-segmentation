{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "device\n",
    "\n",
    "cpu = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = \"./data/train/kidney_1_dense/images\"\n",
    "# labels = \"./data/train/kidney_1_dense/labels\"\n",
    "\n",
    "images = \"./data/train/kidney_1_voi/images\"\n",
    "labels = \"./data/train/kidney_1_voi/labels\"\n",
    "\n",
    "# get each file in the folder\n",
    "image_set = os.listdir(images)\n",
    "label_set = os.listdir(labels)\n",
    "\n",
    "set_length = len(image_set)\n",
    "\n",
    "image_set.sort()\n",
    "label_set.sort()\n",
    "\n",
    "index = random.randint(0, set_length)\n",
    "\n",
    "image = image_set[index]\n",
    "image_name = os.path.join(images, image)\n",
    "\n",
    "label = label_set[index]\n",
    "label_name = os.path.join(labels, label)\n",
    "\n",
    "print (index)\n",
    "print (image_name)\n",
    "\n",
    "image_pil = Image.open(image_name)\n",
    "label_pil = Image.open(label_name)\n",
    "\n",
    "image_tensor = transforms.ToTensor()(image_pil).float()\n",
    "label_tensor = transforms.ToTensor()(label_pil)\n",
    "\n",
    "image_shape = image_tensor.shape\n",
    "print (image_shape)\n",
    "\n",
    "# Find the maximum value in the tensor\n",
    "max_value = torch.max(image_tensor)\n",
    "min_value = torch.min(image_tensor)\n",
    "\n",
    "# # Normalize the tensor by dividing by the maximum value\n",
    "# image_tensor = (image_tensor - min_value) / (max_value - min_value)\n",
    "\n",
    "print (torch.max(image_tensor))\n",
    "print (torch.min(image_tensor))\n",
    "\n",
    "print (image_tensor)\n",
    "\n",
    "# plot the image and label side by side\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "ax = axes.ravel()\n",
    "\n",
    "ax[0].imshow(image_tensor.permute(1, 2, 0))\n",
    "ax[0].set_title(\"Image\")\n",
    "\n",
    "ax[1].imshow(label_tensor.permute(1, 2, 0))\n",
    "ax[1].set_title(\"Label\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rles_file = \"./data/train_rles.csv\"\n",
    "\n",
    "# read the csv file\n",
    "import pandas as pd\n",
    "rles = pd.read_csv(rles_file)\n",
    "rle = rles.iloc[index][\"rle\"]\n",
    "\n",
    "# convert the rle to a mask\n",
    "def rle2mask(rle, shape):\n",
    "    \"\"\"\n",
    "    rle: run-length as string formated (start length)\n",
    "    shape: (height, width) of array to return\n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "    \"\"\"\n",
    "    s = rle.split()\n",
    "    starts = np.asarray(s[0::2], dtype=int)\n",
    "    lengths = np.asarray(s[1::2], dtype=int)\n",
    "    # evaluate whether or not this is needed:\n",
    "    starts -= 1\n",
    "    \n",
    "    ends = starts + lengths\n",
    "\n",
    "    mask = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        mask[lo:hi] = 1\n",
    "\n",
    "    return mask.reshape(shape)\n",
    "\n",
    "# def mask2rle(mask, shape):\n",
    "#     \"\"\"\n",
    "#     mask: numpy array, 1 - mask, 0 - background\n",
    "#     Returns run length as string formatted\n",
    "#     \"\"\"\n",
    "\n",
    "#     mask_1d = mask.reshape(1, shape[0]*shape[1])\n",
    "\n",
    "\n",
    "# convert the rle to a mask\n",
    "mask = rle2mask(rle, (image_shape[1], image_shape[2]))\n",
    "\n",
    "# plot the mask\n",
    "plt.imshow(mask)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            DoubleConv(in_channels, 64),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            DoubleConv(64, 128),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            DoubleConv(128, 256),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            DoubleConv(256, 512),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        self.bottleneck = DoubleConv(512, 1024)\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2),\n",
    "            DoubleConv(1024, 512),\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2),\n",
    "            DoubleConv(512, 256),\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2),\n",
    "            DoubleConv(256, 128),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2),\n",
    "            DoubleConv(128, 64),\n",
    "        )\n",
    "\n",
    "        self.final = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Contracting path (encoder)\n",
    "        encoders = []\n",
    "        for i in range(len(self.encoder)):\n",
    "            module = self.encoder[i]\n",
    "            x = module(x)\n",
    "            if i % 2 == 0:\n",
    "                encoders.append(x)\n",
    "\n",
    "        # Bottleneck\n",
    "        x = self.bottleneck(x)\n",
    "\n",
    "        # Reverse the encoder outputs for the expanding path\n",
    "        encoders = encoders[::-1]\n",
    "\n",
    "        # Expanding path (decoder)\n",
    "        for i in range(len(self.decoder)):\n",
    "            decoder = self.decoder[i]\n",
    "            x = decoder(x)\n",
    "            if i % 2 == 0:\n",
    "                index = i // 2\n",
    "                encoder = encoders[index]\n",
    "\n",
    "                if x.shape != encoder.shape:\n",
    "                    x = transforms.functional.resize(x, size=encoder.shape[2:])\n",
    "                    \n",
    "                x = torch.cat((x, encoder), dim=1)\n",
    "\n",
    "        # Final layer\n",
    "        x = self.final(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "sample = image_tensor.unsqueeze(0).to(device)\n",
    "print (sample.shape)\n",
    "\n",
    "unet = UNet(in_channels=1, out_channels=1).to(device)\n",
    "output = unet(sample)\n",
    "\n",
    "output = output.squeeze(0)\n",
    "plt.imshow(output.permute(1, 2, 0).detach().to(cpu).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_label_set = []\n",
    "\n",
    "for i in range(set_length):\n",
    "    image = image_set[i]\n",
    "    image_name = os.path.join(images, image)\n",
    "\n",
    "    label = label_set[i]\n",
    "    label_name = os.path.join(labels, label)\n",
    "\n",
    "    image_pil = Image.open(image_name)\n",
    "    label_pil = Image.open(label_name)\n",
    "\n",
    "    image_tensor = transforms.ToTensor()(image_pil).float()\n",
    "    label_tensor = transforms.ToTensor()(label_pil)\n",
    "\n",
    "    # max_value = torch.max(image_tensor)\n",
    "    # min_value = torch.min(image_tensor)\n",
    "\n",
    "    # # Normalize the tensor by dividing by the maximum value\n",
    "    # image_tensor = (image_tensor - min_value) / (max_value - min_value)\n",
    "\n",
    "    tensor_label_set.append((image_tensor, label_tensor))\n",
    "\n",
    "random.shuffle(tensor_label_set)\n",
    "print (len(tensor_label_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#Adjust this to take a dir name instead [VK]\n",
    "class KidneyDataset(Dataset):\n",
    "    def __init__(self, tensor_label_set):\n",
    "        self.tensor_label_set = tensor_label_set\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tensor_label_set)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image, label = self.tensor_label_set[index]\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = KidneyDataset(tensor_label_set)\n",
    "\n",
    "# create a dataloader\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# create a model\n",
    "model = UNet(in_channels=1, out_channels=1).to(device)\n",
    "\n",
    "# create a binary cross entropy loss\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# create an optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "num_epochs = 1\n",
    "losses = []\n",
    "for epoch in range(num_epochs):\n",
    "    loop = tqdm(dataloader)\n",
    "    for i, (images_tensors, labels) in enumerate(loop):\n",
    "        # forward pass\n",
    "        outputs = model(images_tensors.to(device))\n",
    "        loss = criterion(outputs, labels.to(device))\n",
    "\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print the loss\n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, len(dataset)//1, loss.item()))\n",
    "        losses.append(loss.item())\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        # plot the loss\n",
    "        plt.plot(losses)\n",
    "        plt.show()\n",
    "                \n",
    "            \n",
    "# save the model\n",
    "torch.save(model.state_dict(), './checkpoints/model.ckpt')\n",
    "\n",
    "# # plot the loss\n",
    "# plt.plot(losses)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model\n",
    "model.eval()\n",
    "\n",
    "# get a random image\n",
    "index = random.randint(0, len(dataset))\n",
    "sample_image, sample_label = dataset[index]\n",
    "\n",
    "print (index)\n",
    "\n",
    "sample_image_tensor = sample_image.unsqueeze(0).to(device)\n",
    "\n",
    "print (sample_image_tensor.shape)\n",
    "\n",
    "# get the output\n",
    "output = model(sample_image_tensor)\n",
    "output_image = output.squeeze(0)\n",
    "\n",
    "print (output_image)\n",
    "\n",
    "# round each value in the output to either 0 or 1\n",
    "output_image_rounded = torch.round(output_image)\n",
    "\n",
    "output_image_sigmoid = torch.sigmoid(output_image)\n",
    "\n",
    "output_image_sigmoid_rounded = torch.round(output_image_sigmoid)\n",
    "\n",
    "# plot the sample, label, and output_image side by side\n",
    "# set color map to binary\n",
    "# plt.rcParams['image.cmap'] = 'binary'\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3)\n",
    "ax = axes.ravel()\n",
    "\n",
    "ax[0].imshow(sample_image.permute(1, 2, 0).detach().to(cpu).numpy())\n",
    "ax[0].set_title(\"Image\")\n",
    "\n",
    "ax[1].imshow(sample_label.permute(1, 2, 0).detach().to(cpu).numpy())\n",
    "ax[1].set_title(\"Label\")\n",
    "\n",
    "ax[2].imshow(output_image_rounded.permute(1, 2, 0).detach().to(cpu).numpy())\n",
    "ax[2].set_title(\"Output\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
